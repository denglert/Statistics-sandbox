{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining bins or channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I use bin and the channel interchangeably.\n",
    "\n",
    "In the case where we have multiple measurements each with the power to constrain a set of parameters, we can collect all the available information into a single object, the combined likelihood function. In case of independent measurements, the combined likelihood is the product of the individual likelihoods:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}\n",
    "=\n",
    "\\prod\\limits_{i=1}^{n}\n",
    "\\mathcal{L}_{i}\n",
    "$$\n",
    "\n",
    "The likelihood in a single bin in most of the cases is described by a Poisson distribution:\n",
    "\n",
    "$$\\mathcal{L}_{i} = \\frac{\\lambda_{i}}{n_{i}} e^{-\\lambda_{i}},$$\n",
    "\n",
    "where $\\lambda$ is the expected number of events in that single bin, and $n_{i}$ is the actual observed number of events.\n",
    "\n",
    "In the context of statistical tests in high energy physics, usually one of the hypothesis includes an additional, distinguished contribution which we regard as the ''signal contribution'' that is described by a signal model. The signal model specifies how many signal events we expect in each channel or bin, denoted by $s_{i}$. This is obviously dependent on luminosity, model parameters etc. We can scale the overall expected number of signal events relative to a nominal signal model using the parameter $\\mu$, which is the signal strength parameter. The motivation for introducing $\\mu$:\n",
    "- the data inherently contains fluctuation, and we would like to to describe these fluctuations with a variable $\\mu$ as well\n",
    "- we can describe both the background only (with $\\mu=0$) and non-zero signal ($\\mu \\neq 0$) scenarios.\n",
    "- in case we want to set an upper limit on the signal cross section, the null-hypothesis, $H_{0}$ is the signal + background model where we can scale the expected number of signal events by $\\mu$ to arrive at a sufficient $p$-value for which we can exclude $H_{0}$.\n",
    "\n",
    "Therefore the expected number of events in a particular hypothesis is described by:\n",
    "\n",
    "$\\lambda_{i} = b_{i} + \\mu s_{i}$\n",
    "\n",
    "where $b_{i}$ is the expected background, $s_{i}$ is the number of signal events in a nominal signal model, and $\\mu$ is just the above defined signal strength parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum likelihood estimator for $\\mu$: $\\hat{\\mu}$\n",
    "\n",
    "The maximum likelihood estimator is defined to be the value of $\\mu$ for which $\\mathcal{L}$ takes its maximum value:\n",
    "\n",
    "$$\\mathcal{L}|_{\\mu = \\hat{\\mu}} = \\mathcal{L}_{max}$$\n",
    "\n",
    "Often it is easier to find the maximum of $\\ln \\mathcal{L}$ instead of $\\mathcal{L}$. Since $\\ln(x)$ is a strictly increasing monoton function of $x$, finding the maximum of $\\ln(\\mathcal{L})$ is the same as finding the maximum of $\\mathcal{L}$:\n",
    "\n",
    "$$\\ln \\mathcal{L}|_{\\mu = \\hat{\\mu}} = \\ln \\mathcal{L}_{max}$$\n",
    "\n",
    "We will use this property in the below derivations.\n",
    "\n",
    "#### Single bin\n",
    "\n",
    "$$\\ln \\mathcal{L}_{i} = n_{i} \\ln (\\lambda_{i}) - \\ln (n_{i}!) - \\lambda_{i} $$\n",
    "\n",
    "\n",
    "Finding $\\hat{\\mu}$ requires us to find the global maximum of $\\ln \\mathcal{L}$. We can examine the local extremums first:\n",
    "\n",
    "$$ \\frac{d \\ln \\mathcal{L}}{ d \\mu} = n_{i} \\frac{1}{\\lambda_{i}} s_{i} - s_{i} = 0$$\n",
    "\n",
    "and we find only one solution:\n",
    "\n",
    "$$ \\hat{\\mu} = \\frac{n_{i} - b_{i}}{s_{i}} $$\n",
    "\n",
    "#### Two bins\n",
    "\n",
    "When we have two independent measurements constraining the same parameter (in this case $\\mu$), we might know from our prior education that the combined best estimate for the parameter will be the uncertainty weighted average:\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{\\mu}\n",
    "=\n",
    "  \\frac{\n",
    "  \\frac{ \\hat{\\mu}_{1} }{ \\sigma^{2}_{\\hat{\\mu}_{1}} }\n",
    "+ \\frac{ \\hat{\\mu}_{2} }{ \\sigma^{2}_{\\hat{\\mu}_{2}} } \n",
    "  }\n",
    "  {   \n",
    "  \\frac{1}{\\sigma^{2}_{\\hat{\\mu}_{1}}}\n",
    "+ \\frac{1}{\\sigma^{2}_{\\hat{\\mu}_{2}}}\n",
    "  }\n",
    "\\text{(Eq. 1)}\n",
    "$$ \n",
    "  \n",
    "and the combined uncertainty:\n",
    "\n",
    "\n",
    "$$\n",
    "\\widetilde{\\sigma}^{2}\n",
    "=\n",
    "  \\frac{\n",
    "  1\n",
    "  }\n",
    "  {   \n",
    "  \\frac{1}{\\sigma^{2}_{\\hat{\\mu}_{1}}}\n",
    "+ \\frac{1}{\\sigma^{2}_{\\hat{\\mu}_{2}}}\n",
    "  }\n",
    "$$ \n",
    "  \n",
    "Knowing this a priori can guide us in the derivation.\n",
    "\n",
    "##### Proof:\n",
    "\n",
    "Here the expected number of events will be:\n",
    "\n",
    "$$\\lambda_{1} = b_{1} + s_{1} \\mu$$\n",
    "\n",
    "$$\\lambda_{2} = b_{2} + s_{2} \\mu$$\n",
    "\n",
    "The log-likelihood:\n",
    "\n",
    "$$\\ln \\mathcal{L} = n_{1} \\ln (\\lambda_{1}) - \\ln (n_{1}!) - \\lambda_{1} + n_{2} \\ln (\\lambda_{2}) - \\ln (n_{2}!) - \\lambda_{2} $$\n",
    "\n",
    "Again, investigating the local extremums:\n",
    "\n",
    "$$\n",
    "\\frac{d \\ln \\mathcal{L}}{ d \\mu}\n",
    "=\n",
    "\\frac{n_{1}}{\\lambda_{1}} s_{1} - s_{1} + \\frac{n_{2}}{\\lambda_{2}}  - s_{2} = 0\n",
    "$$\n",
    "\n",
    "\n",
    "adding and subtracting $b_{i}$ in the numerator, moving the $s_{i}$'s over the other side, and dividing both numerator and denominator by $s^{2}_{i}$:\n",
    "\n",
    "$$\n",
    "\\frac\n",
    "{ \\frac{n_{1}-b_{1}+b_{1}}{s_{1}} }\n",
    "{ \\frac{\\lambda_{1}}{s^{2}_{1}} }\n",
    "+\n",
    "\\frac\n",
    "{ \\frac{n_{2} - b_{2} + b_{2}}{s_{2}} }\n",
    "{ \\frac{\\lambda_{2}}{s^{2}_{2}} }\n",
    "=\n",
    "s_{1} + s_{2}\n",
    "$$\n",
    "\n",
    "moving over $b_{i}$ proportional terms, and the manipulating the RHS:\n",
    "\n",
    "$$\n",
    "\\frac\n",
    "{ \\hat{\\mu}_{1} }\n",
    "{ \\sigma^{2}_{\\hat{\\mu}_{1}} }\n",
    "+\n",
    "\\frac\n",
    "{ \\hat{\\mu}_{2} }\n",
    "{ \\sigma^{2}_{\\hat{\\mu}_{2}} }\n",
    "=\n",
    "s_{1}\n",
    "+\n",
    "s_{2}\n",
    "- \\frac{b_{1}}{\\lambda_{1}} s_{1}\n",
    "- \\frac{b_{2}}{\\lambda_{2}} s_{2}\n",
    "= \n",
    "s_{1}\n",
    "\\left(\n",
    "1\n",
    "- \\frac{b_{1}}{\\lambda_{1}}\n",
    "\\right)\n",
    "+\n",
    "s_{2}\n",
    "\\left(\n",
    "1 - \\frac{b_{2}}{\\lambda_{2}}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "Concentrating on the RHS:\n",
    "\n",
    "$$\n",
    "s_{1}\n",
    "\\left(\n",
    "\\frac{b_{1} - b_{1} + \\mu s_{1}}{\\lambda_{1}}\n",
    "\\right)\n",
    "+\n",
    "s_{2}\n",
    "\\left(\n",
    "\\frac{b_{2} - b_{2} + \\mu s_{2}}{\\lambda_{2}}\n",
    "\\right)\n",
    "=\n",
    "\\mu\n",
    "\\left(\n",
    "\\frac{s^{2}_{1}}{\\lambda_{1}}\n",
    "+\n",
    "\\frac{s^{2}_{2}}{\\lambda_{2}}\n",
    "\\right)\n",
    "=\n",
    "\\mu\n",
    "\\left(\n",
    "\\frac{1}{ \\frac{\\lambda_{1}}{s^{2}_{1}} }\n",
    "+\n",
    "\\frac{1}{ \\frac{\\lambda_{2}}{s^{2}_{2}} }\n",
    "\\right)\n",
    "=\n",
    "\\mu\n",
    "\\left(   \n",
    "  \\frac{1}{\\sigma^{2}_{\\hat{\\mu}_{1}}}\n",
    "+ \\frac{1}{\\sigma^{2}_{\\hat{\\mu}_{2}}}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "Therefore we have:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu}\n",
    "=\n",
    "  \\frac{\n",
    "  \\frac{ \\hat{\\mu}_{1} }{ \\sigma^{2}_{\\hat{\\mu}_{1}} }\n",
    "+ \\frac{ \\hat{\\mu}_{2} }{ \\sigma^{2}_{\\hat{\\mu}_{2}} } \n",
    "  }\n",
    "  {   \n",
    "  \\frac{1}{\\sigma^{2}_{\\hat{\\mu}_{1}}}\n",
    "+ \\frac{1}{\\sigma^{2}_{\\hat{\\mu}_{2}}}\n",
    "  }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected significance after combining channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Competing hypotheses:\n",
    "- $H_{0}$: background only ($\\mu = 0$)\n",
    "- $H_{1}$: signal + background ($\\mu \\neq 0$)\n",
    "\n",
    "#### Channel 1:\n",
    "\n",
    "Expected value of $\\hat{\\mu}_{1}$:\n",
    "\n",
    "$$\\hat{\\mu}_1 = 1$$\n",
    "\n",
    "Expected significance (using the test statistic $g$, [see noteboook][test-stats]):\n",
    "\n",
    "$$\n",
    "Z_{1}\n",
    "=\n",
    "\\frac{\\hat{\\mu}_{1}}{\\sigma_{\\hat{\\mu}_{1}}}\n",
    "=\n",
    "\\frac{1}{\\sigma_{\\hat{\\mu}_{1}}}\n",
    "$$\n",
    "\n",
    "Therefore the uncertainty: $\\sigma_{\\hat{\\mu}_{1}} = \\frac{1}{Z_{1}}$\n",
    "\n",
    "#### Channel 2:\n",
    "\n",
    "Expected value of $\\hat{\\mu}_{2}$:\n",
    "\n",
    "$$\\hat{\\mu}_2 = 1$$\n",
    "\n",
    "Expected significance:\n",
    "\n",
    "$$\n",
    "Z_{2}\n",
    "=\n",
    "\\frac{\\hat{\\mu}_{2}}{\\sigma_{\\hat{\\mu}_{2}}}\n",
    "=\n",
    "\\frac{1}{\\sigma_{\\hat{\\mu}_{2}}}\n",
    "$$\n",
    "\n",
    "Uncertainty: $\\sigma_{\\hat{\\mu}_{2}} = \\frac{1}{Z_{2}}$\n",
    "\n",
    "\n",
    "#### Combination\n",
    "\n",
    "Substituting the values into Eq. 1, we have:\n",
    "\n",
    "$$ \\hat{\\mu} = \\frac{ \\frac{1}{\\sigma^{2}_{\\hat{\\mu}_{1}}} + \\frac{1}{\\sigma^{2}_{\\hat{\\mu}_{1}}} }{ \\frac{1}{\\sigma^{2}_{\\hat{\\mu}_{1}}} + \\frac{1}{\\sigma^{2}_{\\hat{\\mu}_{1}}}  } = 1 $$\n",
    "\n",
    "and the uncertainty on the combined single strength parameter:\n",
    "\n",
    "$$\n",
    "\\widetilde{\\sigma}^{2}\n",
    "=\n",
    "\\frac{ 1 }\n",
    "{ \\frac{1}{\\sigma^{2}_{\\hat{\\mu}_{1}}} + \\frac{1}{\\sigma^{2}_{\\hat{\\mu}_{1}}}  }\n",
    "=\n",
    "\\frac{1}{Z^{2}_{1} + Z^{2}_{2}}\n",
    "$$\n",
    "\n",
    "Expected significance:\n",
    "\n",
    "$$\n",
    "Z_{comb}\n",
    "=\n",
    "\\frac{1}{ \\widetilde{\\sigma}} \n",
    "=\n",
    "\\sqrt{ Z^{2}_{1} + Z^{2}_{2} }\n",
    "$$\n",
    "\n",
    "\n",
    "[test-stats]: ./Simple_single_bin_scenario_expected_upper_limit_test_statistics.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected upper limit  after combining channels\n",
    "\n",
    "Competing hypotheses:\n",
    "- $H_{0}$: signal + background ($\\mu \\neq 0$)\n",
    "- $H_{1}$: background only ($\\mu = 0$)\n",
    "\n",
    "#### Channel 1:\n",
    "\n",
    "Expected value of $\\hat{\\mu}_{1}: 0$\n",
    "\n",
    "Required significance corresponding to 95% CL: $Z = 1.64$\n",
    "\n",
    "Using the test statistic $g$ ([see noteboook][test-stats]):\n",
    "\n",
    "$$\n",
    "Z\n",
    "=\n",
    "\\frac{\\mu^{UL}_{1}}{\\sigma_{\\hat{\\mu}_{1}}}\n",
    "$$\n",
    "\n",
    "Gives us the expected upper limit on $\\mu_{1}$:\n",
    "\n",
    "$$\n",
    "\\mu^{UL}_{1}\n",
    "=\n",
    "Z \\sigma_{\\hat{\\mu}_{1}}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Channel 2:\n",
    "\n",
    "Expected value of $\\hat{\\mu}_{2}: 0$\n",
    "\n",
    "Required significance corresponding to 95% CL: $Z = 1.64$\n",
    "\n",
    "Using the test statistic $g$ ([see noteboook][test-stats]):\n",
    "\n",
    "$$\n",
    "Z\n",
    "=\n",
    "\\frac{\\mu^{UL}_{2}}{\\sigma_{\\hat{\\mu}_{2}}}\n",
    "$$\n",
    "\n",
    "Gives us the expected upper limit on $\\mu_{2}$:\n",
    "\n",
    "$$\n",
    "\\mu^{UL}_{2}\n",
    "=\n",
    "Z \\sigma_{\\hat{\\mu}_{2}}\n",
    "$$\n",
    "\n",
    "#### Combination:\n",
    "\n",
    "Expected value of $\\hat{\\mu}$: $0$.\n",
    "\n",
    "Combined uncertainty:\n",
    "\n",
    "$$\n",
    "\\widetilde{\\sigma}^{2}\n",
    "=\n",
    "\\frac{ 1 }\n",
    "{ \\frac{1}{\\sigma^{2}_{\\hat{\\mu}_{1}}} + \\frac{1}{\\sigma^{2}_{\\hat{\\mu}_{1}}}  }\n",
    "$$\n",
    "\n",
    "The expected upper limit on $\\mu$:\n",
    "\n",
    "$$\n",
    "\\mu^{UL}\n",
    "=\n",
    "Z\n",
    "\\widetilde{\\sigma}\n",
    "$$\n",
    "\n",
    "\n",
    "To give more meaning to this result we remind ourselves that:\n",
    "\n",
    "$$\\sigma^{2}_{\\hat{\\mu}_{i}} = \\frac{\\mu s_{i} + b}{s^{2}_{i}}$$\n",
    "\n",
    "Therefore \n",
    "\n",
    "$$\n",
    "\\mu^{UL}\n",
    "=\n",
    "Z\n",
    "\\frac{1}\n",
    "{\n",
    "\\sqrt{\n",
    "\\frac{s^{2}_{1}}{ b_{1} + \\mu s_{1} } \n",
    "+\n",
    "\\frac{s^{2}_{2}}{ b_{2} + \\mu s_{2} } \n",
    "}\n",
    "}\n",
    "$$\n",
    "\n",
    "and actually here $\\mu^{UL} = \\mu$.\n",
    "\n",
    "[test-stats]: ./Simple_single_bin_scenario_expected_upper_limit_test_statistics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import fsolve\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1950999905732038"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_significance_from_CL(0.975)/1.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_significance_from_CL(CL):\n",
    "    \"\"\"Calculate the significance corresponding to a confidence level\"\"\"\n",
    "    p = 1.0 - CL\n",
    "    Z = norm.isf(p)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_s(b, CL=0.95):\n",
    "    \"\"\"Calculates the x% CL upper limit on the number of signal events\n",
    "    given the expected number of background events.\"\"\"\n",
    "    Z = get_significance_from_CL(CL)\n",
    "    s = 0.5*Z*(Z + np.sqrt(1.0+4.0*b))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mu_ul_eq(mu, s1, b1, s2, b2, CL=0.95):\n",
    "    Z = get_significance_from_CL(CL)\n",
    "    eq = (mu**2) * ( (s1**2/(b1 + mu * s1)) + (s2**2/(b2 + mu * s2)) ) - Z**2\n",
    "    return eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comb_mu_ul(s2b_1, s2b_2, eff1, eff2, lumi, CL=0.95 ):\n",
    "    Z = get_significance_from_CL(CL)\n",
    "    s1 = eff1 * lumi\n",
    "    s2 = eff2 * lumi\n",
    "    b1 = s1 / s2b_1\n",
    "    b2 = s2 / s2b_2\n",
    "    mu = get_mu_ul(s1, b1, s2, b2, CL)\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mu_ul(s1, b1, s2, b2, CL=0.95):\n",
    "    Z = get_significance_from_CL(CL)\n",
    "    mu_sol = fsolve(mu_ul_eq, x0=10.0, args=(s1, b1, s2, b2))\n",
    "    mu_ul = mu_sol[0]\n",
    "    return mu_ul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comb_mu_ul_vec = np.vectorize(comb_mu_ul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 =   1.0\n",
    "b1 =  10.0\n",
    "s2 =   1.0\n",
    "b2 = 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2b_1 = 0.10\n",
    "s2b_2 = 0.01\n",
    "eff1 = 1.0\n",
    "eff2 = 0.1\n",
    "lumi = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1:  1.0\n",
      "b1:  10.0\n"
     ]
    }
   ],
   "source": [
    "s1 = eff1 * lumi\n",
    "b1 = s1 / s2b_1\n",
    "print('s1: ', s1)\n",
    "print('b1: ', b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.6188727899288562"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_s(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.6623877987326683"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_mu_ul(s2b_1, s2b_2, eff1, eff2, lumi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.1599819289118667"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mu_ul(s1, b1, s2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.logspace(-3, 0, 4)\n",
    "y = comb_mu_ul_vec(s2b_1, s2b_2, eff1, a, lumi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb003073860>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7iIiAeh/AU/j6+MkJ357AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb0030a2748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
